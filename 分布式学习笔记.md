# Raft算法

分布式系统采用多台机器存储同一个数据集，不仅可以增强系统的负载能力，而且在单台机器故障的时候，其他机器可以继续提供数据的读写服务，从而提高系统的可用性。Raft算法用于解决如何在不同机器上数据集保持一致。

![image-20230417212539709](分布式学习笔记.assets/image-20230417212539709.png)

## 1. 简单介绍

在raft算法中，每个机器节点的状态包含三种：leader、follower、candidate。系统在时间上被划分为一系列连续的任期term，每个term的leader可以产生连续的log，如下图所示。每个任期term可以选举出一个leader，该term的leader选举出来后可以产生日志。**异常情况下，一些任期term可能选举leader会失败而直接进入下一个term，或者leader没有产生任何日志就超时从而进入下一个选举周期。**

每个raft节点仅需要保存当前leader任期，给谁投过票（保证一个节点不会向多个节点投票），日志。

![image-20230417212606985](分布式学习笔记.assets/image-20230417212606985.png)

leader节点需要将其产生的log复制给其他节点，当多数派节点收到log则表明该log可提交。**对于集群机器更换或者扩缩容，leader节点生成配置变更日志并且复制给其他节点来达成一致。**

此时，Raft算法需要解决三个问题：

1. **raft如何安全地选举出一个leader？**

2. **leader如何将log安全地复制到其他节点？**

3. **集群如何安全地变更机器节点？**

## 2. 如何安全地选举出一个leader？

### 2.1 选举流程

节点初始化的时候，首先进入到follower状态，一段时间内没有收到leader节点的心跳就会切换到candidate状态去竞选leader。节点进入到candidate状态后，首先将自身任期term加一，然后给自己投票，并且向其他节点广播RequestVote投票请求。candidate竞选leader的结果有三种：

1. 拿到多数派投票，切换为leader。

2. 发现其他节点已经是leader（其任期term不小于自身term），则切换为follower。

3. 选举超时后重来一遍选举流程（**比如多个candidate同时参与竞选leader导致每个candidate都拿不到多数派投票**）。

![image-20230417212900539](分布式学习笔记.assets/image-20230417212900539.png)

candidate每次选举时都会设置随机的选举超时时间，避免一直有多个candidate同时参与竞选。candidate竞选成为leader后，就不停地向其他节点广播心跳请求，以维持自己的leader状态同时也为了阻止其他节点切换为candidate去竞选leader。

另外有一种异常情况，**比如某个机器网络故障导致它一直收不到leader的心跳消息，那它就会切换到candidate状态，并且会一直选举超时，那它就会一直增加自身的任期term，当网络恢复正常的时候，原有leader就会收到较高任期term的请求从而被迫切换到follower状态，这样就会影响到整个集群的稳定性**。因此在工程实现的时候，candidate都会增加一个preVote预投票阶段。在预投票阶段，candidate不增加自身term而只会广播投票请求，只有拿到多数派投票后才进入正式投票阶段，这样就可以避免由于网络分区导致集群的term不断增大进而影响集群的稳定性。

最后，因为日志复制只会从leader复制到其他节点，所以在选举的时候，必须确保新leader包含之前任期所有提交的日志。

### 2.2 如何安全选举？

leader选举过程中，候选者candidate发出的投票请求协议。投票请求会带上候选者自身的任期term、candidateId、最新日志的任期term和index，其他节点收到请求后如果发现候选者的任期 >= 自身任期 并且 候选者的最新日志 >= 自身的最新日志，则回复同意。

![image-20230417231408264](分布式学习笔记.assets/image-20230417231408264.png)

　　每条日志的元数据包括任期term以及一个自增的日志索引。日志大小的比较规则是：先比较日志的任期term，term相同则再比较日志的logIndex。

![img](分布式学习笔记.assets/v2-e8e8640e2c2e73f0b16a47a570160c84_720w.png)

　　下面用个例子来证明leader选举的安全性。比如有5台机器，多数派机器拥有最新提交的日志，如果此时有1台机器拿到了多数派投票成为leader，因为两个多数派必然存在交集，所以被选出来的leader，其日志必然 >= 最新提交的日志。因此可以得出1个结论：**新leader节点一定包含最新提交的日志。**

![e64a2fe6-d01b-4441-882b-5f9d0010d594](分布式学习笔记.assets/e64a2fe6-d01b-4441-882b-5f9d0010d594.jpg)

## 3. raft的日志复制以及日志安全性

### 3.1 日志复制请求

leader处理写请求过程中，向其他节点发出的日志复制请求协议。请求会带上leader自己的任期term、LeaderId、本次待复制的日志列表、上一条日志的prevLogIndex和prevLogTerm、已达到多数派一致而提交的最大日志索引commitIndex。**其他节点收到请求后，如果发现leader的任期 >= 自身任期 并且 日志一致性检查通过，则用请求中待复制的日志列表直接覆盖本地的日志，并且更新本地的commitIndex。日志一致性检查的逻辑是：自身节点已存在的日志列表中如果包含请求中指定prevLogIndex、prevLogTerm的日志，则检查通过。**

**某个follower结点未通过一致性检查则返回失败，Leader通过回退prevLogIndex和prevLogTerm直到找到与该follower相同的槽位，然后对follower结点的日志进行覆盖。**

![image-20230417231502714](分布式学习笔记.assets/image-20230417231502714.png)

举个例子，机器节点d作为term 7的leader节点，产生两条日志后发生异常，之后其中一台机器在term 8成功竞选成为leader并生成了一条新日志，这条新日志的logTerm为8，logIndex为11。这个新任leader在将这条新日志复制给其他节点的时候，会带上前一条日志的元数据，也就是prevLogTerm为6，prevLogIndex为10。刚开始由于只有节点c和d包含这个前一条日志而复制成功，其他节点则会拒绝复制。leader节点收到复制失败的回包后，需要往前移动待复制的日志列表然后重新发送日志复制请求。例如leader节点能够成功向节点b复制日志的请求，该请求体的内容为：前一条日志的prevLogTerm为4，prevLogIndex为4，而待复制的日志列表则包含从logIndex为5开始的所有日志。

![image-20230417231642315](分布式学习笔记.assets/image-20230417231642315.png)

**问题1：leader在运行过程中为什么要维护follower的nextIndex和matchIndex**。

**nextIndex 是对追加位置的一种猜测，是乐观的估计**。因此，当 Leader 上任时，会将 nextIndex 全部初始化为 last log index + 1，即乐观地估计所有 Follower 的 log 已经与自身相同。AppendEntries PRC 中，Leader 会根据 nextIndex 来决定向 Follower 发送哪些 entry。当返回失败时，则会将 nextIndex 减一，猜测仅有一条 entry 不一致，再次乐观地尝试。实际上，使用 nextIndex 是为了提升性能，仅向 Follower 发送不一致的 entry，减小 RPC 传输量。

**matchIndex 则是对同步情况的保守确认，为了保证安全性**。matchIndex 及此前的 entry 一定都成功地同步。matchIndex 的作用是帮助 Leader 更新自身的 commitIndex。当 Leader 发现一个 N 值，N 大于过半数的 matchIndex，则可将其 commitIndex 更新为 N（需要注意任期号的问题，后文会提到）。matchIndex 在 Leader 上任时被初始化为 0。

**问题2：客户端向raft集群写数据的具体流程？**

如果客户端想在raft集群中加数据，在AppendEntries中leader会设置prevLogIndex=log[nextIndex-1].index, prevLogTerm=log[nextIndex-1].term，follower会据此判断对应槽位的数据是否和leader相同，如果相同，follower会添加leader日志中[nextIndex,len(log)-1]的数据；不相同则follower向leader返回失败，leader会回退prevLogIndex和prevLogTerm，重新发送AppendEntries。如果在某段时间内leader并未收到超过半数的success，那么他会向客户端返回失败。

![image-20230420000150078](分布式学习笔记.assets/image-20230420000150078.png)

**问题3：假设现在有S2的日志还没提交，Leader就挂掉了怎么办？**

当某个节点的日志还未提交的时候，这块日志可能被大多数节点复制也可能没有，当日志被大多数节点复制的时候，那么这些节点里肯定最有有一个节点会成为leader，这个leader不会直接提交这里的日志，只有在他当前任期有日志的时候一起提交，达到数据的最终一致性。如果这块日志没有被大多数节点复制，那么拥有这些日志的，那么拥有这些日志的节点也不会成为leader（raft中少数服从多数），最后等其他leader上任时会覆盖掉这些日志。

### 3.2 raft的日志匹配性质

日志复制到其他节点后，不同节点上的日志会满足一个匹配性质。不同节点上的两个日志条目，如果logTerm 、logIndex都相同，则有：

1. 由于leader节点对于给定的任期term、给定的logIndex至多创建1个日志条目，那么这两条日志必然包含相同的状态机输入。

2. **因为存在日志复制请求的一致性检查，所以这两个节点上，位于这条相同日志之前的所有日志条目必然也会相同。**

![image-20230417231749433](分布式学习笔记.assets/image-20230417231749433.png)

通过这个日志匹配性质，就可以总结出：**所有节点都会拥有一致的状态机输入序列。这样，各个节点就可以通过一致的初始状态 + 一致的状态机输入序列 从而 得到一致的最终状态。**

### 3.3 raft日志的提交安全性

日志成功复制给多数派节点，就可以提交，进而apply到业务状态机。但日志提交的时候存在一个限制：**不能直接提交之前任期term的日志，只能提交当前任期下的日志。**

下面这个图为例子，在集群处于状态c的时候，节点S1在term 4成为leader，并且已经将term 2的日志复制给多数派，此时节点S1将term 2的日志commit后宕机。之后集群进入到状态d，此时节点S5成为leader并且将term 3的日志复制给其他节点，这样就会导致之前已commit的term 2日志被回滚覆盖。因此为了避免这个问题，之前节点S1在任期term 4的时候，不能直接commit之前任期term的日志，只能通过将自己任期term 4的日志复制给多数派从而commit自己任期内的日志，如图中状态e所示。而一旦自己任期term内的日志得到commit，那么由于日志一致性检查的存在，那么之前任期term下的日志必然也达到了多数派一致，因此之前任期term的日志此时也可以安全地commit。

![image-20230417231837974](分布式学习笔记.assets/image-20230417231837974.png)

### 3.4 快照

快照中包含状态机的状态，还有少量元数据：快照替换日志中最后一个条目的索引和任期，

论文中描述了两种快照算法。

1. 每个节点独立进行快照，leader偶尔需要给落后或者新服务器的follower发送快照（在heartbeat中进行）
2. 只有leader会创建快照，然后发送给每个follower，然而这有两个缺点，浪费带宽和实现复杂。

**问题1：何时快照**

- 上层应用发送快照数据给Raft实例。
- 领导者发送快照RPC请求（直接发送快照数据）给追随者。

**注意当有日志未提交或者要求的快照点已快照则raft会拒绝快照。**Leader在广播过程中如果有follower的快照落后则更新其快照。

**问题2：如果Leader的上层应用刚要求Leader做快照，然后发生网络分区，leader被分在了节点少的区会发生什么（也即Leader做快照需要达成共识吗）**

节点少的这个区也只是会做快照，这一块的数据并没有出错，在网络分区恢复后他的快照和日志会被新leader覆盖。

## 4. raft的集群成员变更

### 4.1 集群成员变更的问题

　　集群在扩缩容或者机器节点发生故障的时候，我们需要对集群的成员进行变更。以下图为例，如果我们直接将集群的节点配置切换到新配置，由于无法将所有节点的配置同时切换到新配置，因此存在某一个时刻，server 1和server 2可以形成老配置的多数派（因为以server1和2的认知，他们仍然认为集群中只有三个结点），server 3、server 4和server 5可以形成新配置的多数派，这样在同一个任期term内就可以选举出两个leader，使得集群产生脑裂。

![image-20230417234638256](分布式学习笔记.assets/image-20230417234638256.png)

　　那么如何解决这种成员变更的问题呢？有两种方式：1. 联合共识。2. 单成员变更。

### 4.2 联合共识-解决集群成员变更问题

此方法允许一次性向集群中插入多个节点而不会出现脑裂等 问题，并且整个集群在配置转换的过程中依然能够接收用户请求，从而实现配置切换对集群调用方无感知。

如下图所示的联合共识中，集群分为三个阶段。

1. 集群还在采用Cold配置，此时Cold配置中的多数派达成一致就可以做出决议。

2. **向集群写入一个Cold,new的配置后，集群进入联合共识状态，此时需要Cold配置中的多数派与Cnew配置中的多数派同时达成一致才可以做出决议。**

3. 向集群写入一个Cnew的配置，集群进入最终状态，此时Cnew配置中的多数派达成一致就可以做出决议。

![image-20230417234350654](分布式学习笔记.assets/image-20230417234350654.png)

**为什么这样可行？**

假设我们产生了2，3分区，分别是（1，2），（3，4，5）

* 如果此时领导者 1 还没有复制任何一条 Cold_new，那么领导者 1 不会应用 Cold_new，(1，2) 分区依然是旧配置，1是领导者；而 (3，4，5) 分区由于 3 会接收心跳超时而发起选举，但是它不会感知到 4，5 的存在，无法获取到大多数节点的投票。因此两个分区只会有一个领导者，符合预期。
* 如果领导者复制了 Cold_new 之后发生了网络分区。如果 Cold_new 没有被大多数节点确认，那么领导者 1 无法应用 Cold_new，(1，2) 依然处于旧配置状态，对外提供服务，此时 (3，4，5) 分区无论谁发起领导者选举，都无法获取到大多数选票(旧配置状态的 3)或者被联合共识 (新配置状态的 4)。
* 如果在 Cnew 阶段产生了分区，由于 raft 算法具有持久性，已经提交的 Cold_new 会永久生效，此时 (A,B) 分区无法获取大多数选票，不会选出新领导者，也就不可能发生脑裂，符合预期。

### 4.3 单成员变更-解决集群成员变更问题

单成员变更的意思就是集群每次只变更一个节点。如下图所示，在单成员变更的方式中，变更前后的两个多数派一定存在交集，也就是变更过程中不可能产生两个leader，因此采用单成员变更的方式，集群不需要引入联合共识的过渡状态。**单节点变更的方式在集群配置变更的过程中是不能对外提供工作的。**

* 网络分区成 (1，2) 和 (3，4) 两部分，如果节点 1，2此时维护的还是旧的配置，那么 1 依旧是领导者，节点 3 因为分区开始发起领导者选举，此时如果 C 维护的是旧的配置 (1，2，3)，那么此时它不会得到节点 D 的投票，无法成为领导者；节点 3 如果维护的是新的配置，那么分区中节点个数不超过一半，它依然不会变成领导者，符合预期。当分区消失之后，节点 D 由于发现自己还没有完成入集群操作，从而会继续向领导者发起“进入集群申请”，领导者便会继续走一遍上述流程。
* 如果节点1，2此时维护的是新配置，那么 (1，2) 分区由于无法获取到大多数选票而无法选出领导者，(3，4) 分区同情况 1，这样的话两个集群都不会成功选举出新的领导者。此时便可能需要人工进行介入，但是集群中依然不会存在两个领导者。
* 1，2，3在同一个分区，剩余的一个节点3在另外一个分区，此时只有包含三节点的分区能选举出领导者，正常处理请求，符合预期。当分区消失了之后，节点 4会正常接收自己缺失的日日志项，从而更新自己维护的配置信息（在这里我们可用发现，节点4虽然已经在集群中，但是在它自己看来，自己确是被孤立的节点）。同样的当分区消失之后，节点 D 会再次申请“进群”。

![image-20230417235028813](分布式学习笔记.assets/image-20230417235028813.png)

**为什么这样可行？**

这里，

![image-20230418004132396](分布式学习笔记.assets/image-20230418004132396.png)

即对于 raft 集群来说，旧配置的大多数与新配置的大多数之和一定大于新配置的节点个数。由于 raft 算法的领导者选举需要获得超过大多数选票，而当我们只新增一个节点的时候，旧配置的大多数和新配置的大多数不可能同时存在（否则必定有至少一个节点同时属于两个分区，这显然是不可能存在的），因此两个分区只有一个分区可能选举出领导者。

**问题1：如果raft要应对集群成员变更，则快照中要包含日志中截至最后包含索引的最新配置。**

## 5. 基于raft层实现容错的键值服务（Fault-tolerant Key/Value Service）

在这里，Raft 层的各种 fault 我们在 lab2 中已经妥善处理了，因此我们主要需要关注的是 Server 层的 fault。

**Server层的fault包括Client和Server之间的RPC丢失、Server直接挂掉（lab3B中的snapshot解决）**

而Client和Server之间RPC丢失最严重的问题是，Client 发送的请求 Server 成功接收，Server 也将请求中的 command 成功在 Raft 层达成共识并应用至状态机，然而在回复 Client 时出现了问题，RPC 回复丢失。这样就有可能**导致一次请求多次重复提交的情况**。

出现这种情况的根本原因是，**Raft 层允许同样的 command commit 多次** (Raft 层并不知道这是不是相同的 command，只要有 command 来，就尝试共识)，但实际上，同样的 command 只能 apply 一次。这就要求客户端为每个命令分配唯一的序列号，为检测重复请求，可在每次请求中加入唯一 id，并随请求自增，再重试时使用同一 id，Server 只需 **对每个 Client 记录最大的请求 id** ，即可排除过期或重复请求。

这里我最开始的想法是Leader的Server层在接收到重复的客户端请求时就查重，那么bug来了，假设现在Leader的完成共识，但是给客户端的回复丢失了，这个时候Leader崩溃或者网络分区丢失了Leader身份，那么其他节点当选时，那么他接收到重复的记录时无法判断。所以，正确方法应该是Leader即使收到了重复的请求也需要达成共识，然后每个节点会自行判断请求是否重复。

**问题1：客户端如何实现数据读写？**

一开始，Client 并不知道 Leader Server 是哪台 Server。Client 可向随机一台 Server 发送 RPC 请求（Server需要达成共识）。假如请求的 Server 不是当前的 Leader Server，或者由于网络中断、Server Crash 等原因，无法与 Server 取得联系，则无限地尝试更换 Server 重新发送请求，直到请求成功被处理。**这里有一个小优化，在得知 Leader Server 后，Client 可以保存 Leader 的 id，避免下次发起请求时又需要随机地选择一台 Server 多次尝试。**

如果 Raft 层长时间无法完成共识 (由于网络分区等原因)，不要让 Server 一直阻塞。及时向 Client 返回 Timeout 错误，使其重新选择另一台 Server 重试。

**问题2：为什么Get需要达成共识？**

如果在Get时仅仅是从Leader中读数据，当出现网络分区时，Leader被划分在少数区，他仍然认为自己是Leader，但其数据并不是最新的，所以我们需要让Get达成共识。

**问题3：为什么客户端的id是随机初始化而不是顺序递增的？**

为什么区分不同的客户端，由于客户端之间是无法意识到对方的存在的，所以需要随机初始化。

**问题4：如果有多个 Client 并行地向 Server 发起请求时，就显然不能保证从 applyCh 传回的数据恰好是此前提交的 command 了**

我们需要在 Server 中对特定的 command 进行等待。raft log 中的 index 区分不同的command。Server 需要维护一张 Map，Key 为 index，Value 为 Server 等待此 index 对应 command 的 channel。

### 5.1 snapshot

前面的工作做好后，加上一个 Snapshot 其实比较简单，在 notifier 中根据 `RaftStateSize()` 和 `MaxStateSize` 的大小关系判断一下是否需要进行一次 Snapshot，并且增加一个分支将 Raft 层传递的 Snapshot 应用至状态机就可以了。

需要注意的是，Snapshot 不仅需要保存 kv database 的信息，还需要保存 maxSeq。因为改变了状态机的状态，就需要状态机相关的 maxSeq 信息来拦截重复请求。在应用 Snapshot 时，状态机状态发生改变，所以也需要将 maxSeq 与 Leader 的 maxSeq 进行同步。

## 6. Sharded Key/Value Service

这里需要实现一个分区的kv存储服务，分为ShardMaster和ShardKv两部分：一个raft group运行ShardMaster，负责维护分区配置信息；多个raft group运行ShardKv，分别存储零至多个分区的数据，也就是常说的multi-raft。

### 6.1 分区算法

从key到分区的映射，lab已经为我们准备好了，是简单地对key取模。

从分区到节点 (raft group) 的映射，lab使用固定数量的分区，分区总数为NShards，不需要分区合并或分裂。固定数量分区一般分区数量远大于节点数，lab里NShards是10，节点数一般为3。

lab要求分区在平衡时要保证转移的分区数量最少，所以这里使用简单的多削少补的方法，复杂度O(n)。这里没有使用一致性哈希，因为一致性哈希的节点位置是随机选择的，并不能保证转移的分区数量最少。

### 6.2 ShardedKv状态

lab希望对一个分区的转移不影响其他分区，所以我在ShardKv里为每一个shard维护了如下结构：

```text
KvMap           map[string]string
DupMap          map[int64]uint32
Valid           bool
```

KvMap维护kv数据；DupMap为client请求去重；Valid维护当前ShardKv是否可以对shard进行读写。

并且每个ShardKv维护一个

```text
ConfigNumber    int
```

表示该ShardKv目前处于哪一个Config中。

### 6.3 处理乱序和重复

#### 6.3.1 command处理乱序与重复

lab3已经处理了put、append、get的乱序和重复，lab4中对这三种操作只需要简单地在apply时检查当前ShardKv是否负责对key所在shard读写。

对于其他的command，即涉及分区转移的command，在apply时全部需要处理重复与乱序。

不论具体实现方式，所有ShardKv的实现都涉及到以下三种command语义：

（1）使自己的某个shard开始提供服务；

（2）使自己的某个shard停止提供服务；

（3）使自己的遵循的ConfigNumber变化。

以上某种command能够apply到状态机，是因为之前某处检查了状态机的状态，start该command。然而start该command时所检查的状态，并不一定是该command apply时的状态，即start获得的index下的真正状态。

不管是apply时检查状态，还是外部的协程检查的状态，都无法保证是start所获得index下的真正状态。所以笔者没有实现check语义的command，或者apply时检查状态。而是选择在外部的协程检查状态进行start command。

#### 6.3.2 raft group之间rpc处理乱序与重复

因为raft group之间rpc是在外部的协程检查状态，并且不能得到状态机的真正状态，所以只能用要检查的状态之后的状态cover所检查的状态，而不能舍弃rpc。

举个栗子，有三个状态

```text
A->B->C
```

如果需要状态机处于状态B才能执行rpc的命令，那么在rpc入口：

（1）检查状态为A，不能舍弃rpc；

（2）检查状态为B，不能舍弃rpc；

（3）检查状态为C，可以视作重复，舍弃rpc，返回OK。

如果要检查状态为A就舍弃rpc，即放弃start某种command，那么需要满足两个条件：（1）不断循环尝试；（2）目标raft group必然会到达状态B。

#### 6.4 分区转移实现

分区转移有两种实现方式：

（1）旧的持有者向新的持有者push分区；

（2）新的持有者向旧的持有者pull分区。

两种实现方式都是可以的，为了保证线性，只需要旧的持有者提供分区之前，停止该分区的对外服务，即apply停止这个分区服务的command。

不同点在于，如果要实现TestChallenge1Delete，方法（1）旧的持有者在push成功之后可以直接start删除分区数据的command；

方法（2）新的持有者在pull分区之后，需要start一个command使分区分布在raft group内并且提供服务，apply该command之后需要额外发送一种新的rpc使旧的持有者删除分区。

## 性能

## lab2中遇到的坑点

1. 之前的代码只是简单的在倒计时结束后发生选举，导致**超时之后，程序执行至rf.lock() ，而此时，节点正在处理 RequestVote RPC，因此 rf.lock() 被阻塞；当节点将选票投给了另一个 Candidate 节点，退出 RPC handler，然后 alerter 协程成功抢占到了锁——悲剧发生了。刚刚投出选票的节点，立马发起了新一轮的选举。**

2. 安装快照的时候应该抛弃之前的日志，但是我之前只是简单的截取切片。**在截取 slice 时，实际上没有创建新的数组，只是改变了引用的范围。但比较坑的是，即使此后仅会使用某个范围内的元素，整个数组也不会被 gc 回收，而是一直保留，最后造成 oom。**

## lab3中遇到的坑点

1. 客户端向Leader请求某个操作，Leader需要达成共识，所以Leader的Raft层完成操作后需要向Server层回复是否成功，Server层再向客户端回复，而follower节点时不需要的。而bug来了，**某个节点从follower转为leader时还存在已提交到日志但是没有应用的log，这些日志在应用时按照我之前的代码会向Server回复，这里是利用通道操作所以会造成阻塞。**所以这里需要在代码中做个条件判断，当应用的日志任期和当前Leader任期相等的时候才会向Server转发操作成功的

## lab4中遇到的坑点

1. 如果ShardMaster分区再平衡时，直接在apply leave或join处计算新的config，并且算法对map进行遍历，可能因为go map遍历顺序随机，不同的raft节点计算出的config不同。解决需要对key排序，顺序遍历。

2. 

   ```text
   r := bytes.NewBuffer(data)
   d := labgob.NewDecoder(r)
   d.Decode(&someMap)
   ```

   如果data中的map为空，那么反序列化得到的someMap依旧为原来的someMap。这会使读snapshot时已经删除的shard依然可能存在。

# 其他

## 分布式事务

分布式事务是指跨越多个计算机和网络的多个操作同时满足ACID（原子性、一致性、隔离性和持久性）属性的事务。在分布式系统中，一个完整的业务操作可能需要跨越多个节点或数据库，而分布式事务的目标就是确保这些操作的原子性和一致性，即要么全部成功，要么全部失败并回滚。常见的分布式事务协议有两阶段提交（2PC）、三阶段提交（3PC）等。

1. 2PC。事务的提交被分为两个阶段。在第一个阶段（投票阶段），所有参与者将准备好提交事务。在第二个阶段（提交阶段），协调者会根据第一个阶段的投票结果通知参与者是否提交或者回滚该事务。如果协调者决定提交该事务，则所有参与者都将提交该事务。否则，所有参与者都将回滚该事务。
2. 2PL用于确保并发事务的正确性和一致性。在2PL中，锁被用来控制对共享资源的访问，以避免并发事务之间的干扰。2PL分为两个阶段，即加锁阶段和解锁阶段。在加锁阶段，事务需要请求并获取所需的锁，并保持锁的状态，以防止其他事务对该资源进行修改。在解锁阶段，事务会释放已经获取的锁，使其他事务可以对该资源进行修改。
3. 3PC。在2PC中，如果协调者（Coordinator）出现故障，可能会导致参与者（Participants）永久地阻塞，因为它们无法知道事务是否提交或中止。
   3PC尝试解决这个问题，将2PC中的“准备”阶段分为两个阶段：CanCommit和PreCommit（第三个阶段未DoCommit），并在CanCommit和PreCommit之间增加了超时机制，即“超时等待”阶段。
   具体来说，当协调者向参与者发送CanCommit请求后，如果参与者同意提交，则发送Yes消息；如果参与者拒绝提交，则发送No消息。如果协调者在超时时间内收到了所有参与者的Yes消息，则会进入PreCommit阶段，向所有参与者发送PreCommit请求。如果参与者同意提交，则发送Ack消息；如果参与者拒绝提交，则发送Abort消息。如果协调者在超时时间内收到了所有参与者的Ack消息，则提交操作；否则，协调者向所有参与者发送Abort请求，撤销操作。
